---
published: false
---
This post is dedicated to all you lucid dreamers.

It's the covergent evolution of three recent encounters with one question: what are the computational limits of the human brain?

Encounter 1 (~ 1 week ago): I first started thinking about this while reading an entirely unrelated essay from Rationality: AI to Zombies. In Book 2, Yudkowski makes the following statement:

> Unsurprisingly, the human brain doesn’t do 64-bit floating-point arithmetic, and it can’t devalue the emotional force of a pleasant anticipation by a factor of 0.00000001 without dropping the line of reasoning entirely.

When read in context, it's found in a section that really has nothing to do with computational limits (it's an esssay on lotteries, of all things). But my mind started to wander, and it stuck with me. If the brain doesn't do "64-bit floating point arithmetic"... then what __can__ it do?

And how fast can it do it (__it__ being some sort of basic, singular mental computation)?

An interesting thought, but other things came up that day and I let it go.

Encounter 2 (~ 3 days ago): These two questions were narrowed down a few days later. I was talking about lucid dreaming with a friend (Lucas Rosen). More specifically, we were talking about the brain's remarkable ability to conjure up entire personalities and landscapes seemingly on command while we dream. 

Remembering the thought I had while reading Yudkowski, I stopping the marveling and sketched out the following scenario for Lucas:

Imagine you're in a lucid dream.

You're suspended 5,000 feet above an endless city, laid upon an endless plane (we'll say it's a flat-earth version of an ecumenopolis like Coruscant).

Your only option is to fly forward, but you can vary the speed at which you do so.

We assume that your dream runs in real-time, or if not, that at least mental computations occur at fixed intervals.

If you started moving forward, ever accelerating, would you ever reach a point where your mind can't keep up computationally, and starts "lagging" or "dropping frames"?

We were intrigued.

Encounter 3 (~ 2 days ago): 

Before I even had the chance to read into anything on the brain's computational limits I ran into the topic one final time, this time in an SSC post on DMT entities:

> 	“Universal love,” said the cactus person.
	“Transcendent joy,” said the big green bat.
	“Right,” I said. “I’m absolutely in favor of both those things. But before we go any further,  		could you tell me the two prime factors of 1,522,605,027, 922,533,360, 535,618,378, 			132,637,429, 718,068,114, 961,380,688, 657,908,494 ,580,122,963, 258,952,897, 654,000,350, 		692,006,139?

Check out the SSC post for context. What matters for this post is that it riled me up again. What __could__ we factor in a dream?

So, at the end of the week I was left with this burining, unanswered question about how complex our dreams can get.

And so I set about trying to amass enough literature on the subject that I might get a general idea of whether those limits exist, and if they do where the qualitative/quantitative boundaries lie.

One strategy for making sense of the unknown is to relate it to a well-understood analogue. In the case of the brain, we can, as many have, relate it to a Turing machine (the stance known as the "classical computational theory of mind"). But this comparison has several shortcomings. Stanford's Encyclopedia of Philosophy lays them out rather clearly:

> Turing machines execute pure symbolic computation. The inputs and outputs are symbols inscribed in memory locations. In contrast, the mind receives sensory input (e.g., retinal stimulations) and produces motor output (e.g., muscle activations). A complete theory must describe how mental computation interfaces with sensory inputs and motor outputs.

> A Turing machine has infinite discrete memory capacity. Ordinary biological systems have finite memory capacity. A plausible psychological model must replace the infinite memory store with a large but finite memory store

> Modern computers have random access memory: addressable memory locations that the central processor can directly access. Turing machine memory is not addressable. The central processor can access a location only by sequentially accessing intermediate locations. Computation without addressable memory is hopelessly inefficient. For that reason, C.R. Gallistel and Adam King (2009) argue that addressable memory gives a better model of the mind than non-addressable memory.

> A Turing machine has a central processor that operates serially, executing one instruction at a time. Other computational formalisms relax this assumption, allowing multiple processing units that operate in parallel. Classical computationalists can allow parallel computations (Fodor and Pylyshyn 1988; Gallistel and King 2009: 174). See Gandy (1980) and Sieg (2009) for general mathematical treatments that encompass both serial and parallel computation.

> Turing computation is deterministic: total computational state determines subsequent computational state. One might instead allow stochastic computations. In a stochastic model, current state does not dictate a unique next state. Rather, there is a certain probability that the machine will transition from one state to another.

So the mind is less like a Turing machine... and more like a modern computer. It has finite memory (read: limit #1, and that memory includes some RAM- or VRAM-esque component, we'll get to that division soon) and computations are executed in a nonzero amount of time (read: limit #2). There's simple physiological proof supporting that second limiation

A brief aside on the representational theory of mind: There's so much more to say about exacltly __how__ the brain processes data, but the one theory I run with in this post is the representational theory of mind.

So, we've found two hard limits to concentrate on if we want to find where your lucid dream could "break":
	1. 



We know, however, that dreams don't happen in real time. When you're 